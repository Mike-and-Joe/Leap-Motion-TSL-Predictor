{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import GRU, Dense, Dropout, Input, concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import datetime\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variable\n",
    "words = [\n",
    "    'come quickly', 'emergency', 'father', 'fever', 'good luck',\n",
    "    'headache', 'hello', 'help', 'hi', 'hungry',\n",
    "    'like', 'mother', 'mother_father', 'mother_mother', 'not ok',\n",
    "    'quickly', 'sorry', 'tomorrow', 'yogurt'\n",
    "]\n",
    "data_per_word = 27\n",
    "# data_length = data_per_word * len(words)\n",
    "speedup_max = 1.15\n",
    "timesteps = 50\n",
    "augment_timesteps = math.ceil(timesteps * speedup_max) # add speedup\n",
    "dimensions = 34 #22 #34\n",
    "pick_frame_every_no = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./extracted_feature/original_full_32_dimensions_GridSearch.pkl', 'rb') as handle:\n",
    "    [x_original, y_original, x_augment] = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [\n",
    "#     {\n",
    "#         \"hands\": {\n",
    "#             \"right\": {\n",
    "#                 \"arm\": {\n",
    "#                     \"direction\": [x,y,z]\n",
    "#                 }\n",
    "#                 \"hand_palm_position\": [x,y,z],\n",
    "#                 \"roll\": n,\n",
    "#                 \"yaw\": n,\n",
    "#                 \"pitch\": n,\n",
    "#                 \"fingers\": {\n",
    "#                     \"pinky\": {\n",
    "#                         \"bones\": {\n",
    "#                             \"distal\": {\n",
    "#                                 \"next_joint\": [x,y,z]\n",
    "#                             },\n",
    "#                             \"proximal\": {\n",
    "#                                 \"direction\": [x,y,z]\n",
    "#                             }\n",
    "#                         }\n",
    "#                     }\n",
    "#                 }\n",
    "#             }\n",
    "#         }\n",
    "#     }\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_feature(frame):\n",
    "    finger_name = ['thumb', 'index', 'middle', 'ring', 'pinky']\n",
    "    hand_name = ['left', 'right']\n",
    "    \n",
    "    fingertip_pos = np.zeros([2, 5, 3])\n",
    "    \n",
    "    hand_palm_pos = np.zeros([2, 3])\n",
    "    hand_palm_rpy = np.zeros([2, 3])\n",
    "    hand_palm_unit_vector = np.zeros([2, 3])\n",
    "    arm_direction = np.zeros([2, 3])\n",
    "    \n",
    "    feature = np.zeros([34])\n",
    "    \n",
    "    for hand_idx, hand in enumerate(hand_name):\n",
    "        if not hand in frame['hands']:\n",
    "            continue\n",
    "        hand_palm_pos[hand_idx] = np.array(frame['hands'][hand]['hand_palm_position'])\n",
    "        hand_palm_rpy[hand_idx] = np.array([ frame['hands'][hand]['roll'],\n",
    "                                                    frame['hands'][hand]['pitch'],\n",
    "                                                    frame['hands'][hand]['yaw']])\n",
    "#         hand_palm_unit_vector[hand_idx] = np.cross(\n",
    "#             frame['hands'][hand]['fingers']['index']['bones']['proximal']['direction'],\n",
    "#             frame['hands'][hand]['fingers']['middle']['bones']['proximal']['direction']\n",
    "#         )\n",
    "#         arm_direction[hand_idx] = np.array(frame['hands'][hand]['arm']['direction'])\n",
    "        for finger_idx, finger in enumerate(finger_name):\n",
    "            fingertip_pos[hand_idx, finger_idx] = (\n",
    "                np.array(frame['hands'][hand]['fingers'][finger]['bones']['distal']['next_joint'])\n",
    "            )\n",
    "            \n",
    "    fingertip_pos_shift = np.roll(fingertip_pos, 1, axis=1)\n",
    "    dist_btw_fingertip = np.linalg.norm(fingertip_pos - fingertip_pos_shift, axis=2)\n",
    "        \n",
    "    feature[0:6] = hand_palm_pos.reshape(6)\n",
    "    feature[6:12] = hand_palm_rpy.reshape(6)\n",
    "    feature[12:22] = dist_btw_fingertip.reshape(10)\n",
    "#     feature[22:28] = hand_palm_unit_vector.reshape(6)\n",
    "#     feature[28:34] = arm_direction.reshape(6)\n",
    "    \n",
    "    return feature\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_timesteps(json_data, pick_frame_every_no): \n",
    "    timesteps = np.zeros([0, dimensions])\n",
    "    for frame_no, frame in enumerate(json_data):\n",
    "        if frame_no % pick_frame_every_no != 0 or not frame['hands']:\n",
    "            continue\n",
    "        feature = get_feature(frame)\n",
    "        timesteps = np.vstack((timesteps, feature))\n",
    "    return timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_x_norm(x):\n",
    "    x_std = x.std(axis=(0,1), keepdims=True)\n",
    "    x_mean = x.mean(axis=(0,1), keepdims=True)\n",
    "    x_norm = (x-x_mean)/x_std\n",
    "    return x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_x_augment_custom(x_augment = x_augment):\n",
    "    x_augment_custom = {}\n",
    "    for key, pack in x_augment.items():\n",
    "        x_augment_custom[key] = pack[:,:,0:22]\n",
    "    return x_augment_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mike\\Anaconda3\\lib\\site-packages\\keras\\models.py:291: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "file_name = 'model_grid_search_[0.85, 0.9, 1.0, 1.1, 1.15]_128_1_Note_try old features'\n",
    "\n",
    "try:\n",
    "    f = h5py.File('./interested_model/'+ file_name +'.h5', 'r+')\n",
    "    del f['optimizer_weights']\n",
    "    f.close()\n",
    "except:\n",
    "    None\n",
    "\n",
    "model = load_model(\"./interested_model/\"+ file_name +\".h5\")\n",
    "# with open('./interested_model/history_'+ file_name +'.pkl', 'rb') as handle:\n",
    "#     history = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_x():\n",
    "    timesteps = augment_timesteps\n",
    "    x_original = np.zeros([0, timesteps, dimensions])\n",
    "    word = 'emergency'\n",
    "    data_per_word = 27\n",
    "    \n",
    "    for data_no in range(data_per_word):\n",
    "        try:\n",
    "            with open(\"./record/{}/json_{}.txt\".format(word, data_no)) as json_data:\n",
    "                json_data = json.load(json_data)\n",
    "        except Exception as s:\n",
    "            print ('error log:', s)\n",
    "\n",
    "        _timesteps = get_timesteps(json_data, pick_frame_every_no)\n",
    "        _timesteps = np.vstack((_timesteps, np.zeros([timesteps - _timesteps.shape[0], dimensions])))\n",
    "        x_original = np.vstack((x_original, [_timesteps]))\n",
    "        \n",
    "    return x_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_x2():\n",
    "    data = []\n",
    "    word = 'emergency'\n",
    "    data_per_word = 1\n",
    "    \n",
    "    for data_no in range(data_per_word):\n",
    "        try:\n",
    "            with open(\"./record/{}/json_{}.txt\".format(word, data_no)) as json_data:\n",
    "                json_data = json.load(json_data)\n",
    "        except Exception as s:\n",
    "            print ('error log:', s)\n",
    "        \n",
    "        data.append(json_data)\n",
    "        \n",
    "    return sampling_x(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sampling_x(data):\n",
    "    timesteps = augment_timesteps\n",
    "    x_original = np.zeros([0, timesteps, dimensions])\n",
    "    \n",
    "    for pack in data:\n",
    "        _timesteps = get_timesteps(pack, pick_frame_every_no)\n",
    "        _timesteps = np.vstack((_timesteps, np.zeros([timesteps - _timesteps.shape[0], dimensions])))\n",
    "        x_original = np.vstack((x_original, [_timesteps]))\n",
    "        \n",
    "    return x_original\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(x_test):\n",
    "    x_std = x_original.std(axis=(0,1), keepdims=True)\n",
    "    x_mean = x_original.mean(axis=(0,1), keepdims=True)\n",
    "\n",
    "#     print(x_test.shape)\n",
    "    \n",
    "    x_predict = x_test\n",
    "    x_predict = (x_predict-x_mean)/x_std\n",
    "    x_predict = x_predict[:,:,0:22]\n",
    "\n",
    "#     print(x_predict.shape)\n",
    "    prediction = model.predict(x_predict, verbose = 1)\n",
    "#     print('prediction', prediction)\n",
    "    \n",
    "    result_text = []\n",
    "    \n",
    "    prediction_word_index = np.argmax(prediction, axis = 1)\n",
    "    \n",
    "    for ans in prediction_word_index:\n",
    "        result_text.append(words[ans])\n",
    "    \n",
    "#     print('result_text', result_text)\n",
    "    \n",
    "    return result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_with_data(data):\n",
    "    x_predict = sampling_x(data)\n",
    "    \n",
    "    return predict(x_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_predict():\n",
    "    with open('./extracted_feature/original_test_set_2.pkl', 'rb') as handle:\n",
    "        [x_3rd_user, y_3rd_user, x_3rd_user_augment] = pickle.load(handle)\n",
    "    \n",
    "    predict(x_3rd_user_augment[1.00][0:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_predict2():\n",
    "    x_predict = get_x2()\n",
    "    \n",
    "    predict(x_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_predict3(word = 'hi', index = 1):\n",
    "    data = []\n",
    "    data_per_word = index\n",
    "    \n",
    "    for data_no in range(data_per_word):\n",
    "        try:\n",
    "            with open(\"./record/{}/json_{}.txt\".format(word, data_no)) as json_data:\n",
    "                json_data = json.load(json_data)\n",
    "        except Exception as s:\n",
    "            print ('error log:', s)\n",
    "        \n",
    "        data.append(json_data)\n",
    "\n",
    "    return predict_with_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step\n",
      "res : ['hi']\n"
     ]
    }
   ],
   "source": [
    "print('res :', test_predict3())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
